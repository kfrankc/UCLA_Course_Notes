# Mathematical Theory of Communication, 1963

### 2. The Discrete Source of Information
* log of the no. of possible signals in discrete channel increases linearly with time
* Sometimes, we can predict
 * ex. letter E occurs more than Q
* A discrete source is represented by a stochastic process.  

**Examples:**  
1. Natural Written Languages
2. Continuous Information Sources
3. Mathematical cases:
 * 5 letters (A, B, C, D, E), chosen with probability 0.2
 * or, using different probabilities on each
 * or, symbols are not chosen independently, but depend on preceding letters
 * Review page 48 of the Shannon readings
 * or, probabilities that are mapped to sequences of words
 * 2nd order approximations have the introduction of diagram structures
  * after letter is chosen, the next one is chosen in acoordance with the frequencies with which the various letters follow the first one